Mini LLM System com Gemini API

Este projeto √© um assistente de IA simples, constru√≠do com Flask e Python, que utiliza a API do Google Gemini para interpretar as solicita√ß√µes do usu√°rio e interagir com o sistema local. O assistente pode executar comandos de shell, criar e ler arquivos, al√©m de manter conversas normais.

‚ú® Funcionalidades

Intelig√™ncia Artificial Conversacional: Utiliza o modelo gemini-2.0-flash para entender e responder √†s solicita√ß√µes do usu√°rio.

Execu√ß√£o de Comandos: Pode executar comandos de shell (como ls, pwd, echo) diretamente no servidor onde a aplica√ß√£o est√° rodando.

Manipula√ß√£o de Arquivos: Capaz de criar novos arquivos com conte√∫do espec√≠fico e ler o conte√∫do de arquivos existentes.

Download de Arquivos: Oferece um endpoint para que o usu√°rio possa baixar os arquivos criados pelo assistente.

Filtro de Seguran√ßa: Inclui uma camada de seguran√ßa b√°sica que bloqueia a execu√ß√£o de comandos potencialmente perigosos que poderiam afetar o sistema operacional.

Interface Web: Fornecido com um backend Flask pronto para ser integrado a um frontend de chat.

‚öôÔ∏è Como Funciona

O fluxo da aplica√ß√£o √© o seguinte:

O usu√°rio envia uma mensagem atrav√©s de uma interface web (frontend).

O backend Flask recebe a mensagem no endpoint /chat.

A mensagem √© enviada para a API do Gemini, juntamente com um "prompt de sistema" que instrui o modelo sobre suas capacidades e as ferramentas (execute_command, create_file, read_file) que ele pode usar.

O Gemini analisa a solicita√ß√£o:

Se for uma pergunta ou conversa, ele gera uma resposta em texto.

Se for uma tarefa (ex: "liste os arquivos"), ele retorna uma "chamada de fun√ß√£o" (functionCall) com o nome da ferramenta e os argumentos necess√°rios.

O backend Python executa a fun√ß√£o solicitada pelo Gemini (se houver), captura o resultado e o retorna ao usu√°rio.

A resposta final √© exibida na interface do usu√°rio.

üöÄ Instala√ß√£o e Configura√ß√£o

Siga os passos abaixo para executar o projeto em seu ambiente local.

Pr√©-requisitos

Python 3.7 ou superior

Pip (gerenciador de pacotes do Python)

Uma chave de API do Google Gemini (obtenha em Google AI Studio)

Passos

Clone o reposit√≥rio:

git clone https://seu-repositorio/mini-llm-system.git
cd mini-llm-system


Crie e ative um ambiente virtual (recomendado):

python -m venv venv
# Windows
.\venv\Scripts\activate
# macOS/Linux
source venv/bin/activate


Instale as depend√™ncias:
Crie um arquivo requirements.txt com o seguinte conte√∫do:

Flask
Flask-Cors
requests


E instale-o com o pip:

pip install -r requirements.txt


Configure a sua Chave de API:
Abra o arquivo principal Python (app.py ou similar) e substitua o placeholder "CHAVE DE API" pela sua chave de API do Google Gemini.

# Altere esta linha
GEMINI_API_KEY = "SUA_CHAVE_DE_API_VEM_AQUI"


‚ñ∂Ô∏è Como Executar

Inicie o servidor Flask:

python seu_arquivo.py


Acesse a aplica√ß√£o:
Abra seu navegador e acesse http://127.0.0.1:5000. Voc√™ dever√° ver a interface de chat (index.html).

Interaja com o assistente:
Voc√™ pode experimentar diferentes tipos de comandos:

Comando de Shell: "Liste os arquivos e pastas no diret√≥rio atual."

Cria√ß√£o de Arquivo: "Crie um arquivo chamado 'lista.txt' com o conte√∫do: Ma√ß√£, Banana, Laranja"

Leitura de Arquivo: "Leia o conte√∫do do arquivo 'lista.txt'"

Conversa: "Qual √© a capital do Brasil?"

Endpoints da API

GET /: Renderiza a p√°gina principal de chat (index.html).

POST /chat: Recebe a mensagem do usu√°rio em formato JSON ({"message": "sua mensagem"}) e retorna a resposta do assistente.

GET /download/<filename>: Permite o download de um arquivo que foi criado na sess√£o.

‚ö†Ô∏è Nota de Seguran√ßa

Este projeto permite a execu√ß√£o de comandos de shell remotamente, o que √© uma funcionalidade inerentemente perigosa. Embora exista uma lista de bloqueio para comandos cr√≠ticos (rm -rf, shutdown, etc.), ela pode n√£o ser exaustiva.

Execute este projeto em um ambiente controlado e isolado. N√£o o exponha publicamente na internet sem implementar camadas robustas de seguran√ßa e autentica√ß√£o.

Este README foi gerado para auxiliar na documenta√ß√£o e uso do projeto Mini LLM System.
